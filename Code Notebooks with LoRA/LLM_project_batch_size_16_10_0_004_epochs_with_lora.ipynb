{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pToAIIlAJB87"
      },
      "source": [
        "# Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9unc-ddJJB88",
        "outputId": "7b66c234-ec94-4f3f-b86f-3a24219a11ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire==0.5.0\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire==0.5.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire==0.5.0) (2.4.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=2cc4f1ddd49d49979baed020fc26bb5744d3ddb606057258d10f75506245cf90\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.5.0\n",
            "Collecting pydantic==1.10.6\n",
            "  Downloading pydantic-1.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.6) (4.11.0)\n",
            "Installing collected packages: pydantic\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "Successfully installed pydantic-1.10.6\n",
            "Collecting pytorch-lightning==2.0.0\n",
            "  Downloading pytorch_lightning-2.0.0-py3-none-any.whl (715 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.6/715.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.0) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.0) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.0) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.0) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==2.0.0)\n",
            "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.0) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.0) (4.11.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning==2.0.0)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.7.0->pytorch-lightning==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.0) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.0) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->pytorch-lightning==2.0.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting pretty-errors==1.2.25 (from torchmetrics>=0.7.0->pytorch-lightning==2.0.0)\n",
            "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
            "Collecting colorama (from pretty-errors==1.2.25->torchmetrics>=0.7.0->pytorch-lightning==2.0.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning==2.0.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.0.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning==2.0.0) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "Successfully installed colorama-0.4.6 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 pytorch-lightning-2.0.0 torchmetrics-1.4.0\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.4-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n",
            "Collecting tqdm==4.65.0\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.2\n",
            "    Uninstalling tqdm-4.66.2:\n",
            "      Successfully uninstalled tqdm-4.66.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.65.0\n",
            "Collecting transformers==4.28.1\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2024.2.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.1\n",
            "    Uninstalling transformers-4.40.1:\n",
            "      Successfully uninstalled transformers-4.40.1\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.28.1\n",
            "Collecting safetensors==0.3.0\n",
            "  Downloading safetensors-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.4.3\n",
            "    Uninstalling safetensors-0.4.3:\n",
            "      Successfully uninstalled safetensors-0.4.3\n",
            "Successfully installed safetensors-0.3.0\n",
            "Collecting datasets==2.11.0\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (14.0.2)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.11.0)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (4.65.0)\n",
            "Collecting xxhash (from datasets==2.11.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.11.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (24.0)\n",
            "Collecting responses<0.19 (from datasets==2.11.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.11.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.11.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.11.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.11.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.11.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.11.0) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.11.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.11.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.11.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.11.0) (2024.2.2)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.11.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.11.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.11.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.11.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.11.0) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
            "Successfully installed datasets-2.11.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.4.1\n",
            "Collecting git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision e536616888d51b453ed354a6f1e243fecb02ea08) to /tmp/pip-req-build-u9acv5ro\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-u9acv5ro\n",
            "  Running command git rev-parse -q --verify 'sha^e536616888d51b453ed354a6f1e243fecb02ea08'\n",
            "  Running command git fetch -q https://github.com/huggingface/peft.git e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "  Running command git checkout -q e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "  Resolved https://github.com/huggingface/peft.git to commit e536616888d51b453ed354a6f1e243fecb02ea08\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0.dev0) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0.dev0) (4.28.1)\n",
            "Collecting accelerate (from peft==0.3.0.dev0)\n",
            "  Downloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.3.0.dev0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.3.0.dev0) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.3.0.dev0) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.3.0.dev0) (18.1.4)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->peft==0.3.0.dev0) (0.20.3)\n",
            "Collecting safetensors>=0.3.1 (from accelerate->peft==0.3.0.dev0)\n",
            "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.3.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.3.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.3.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.3.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate->peft==0.3.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.3.0.dev0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.3.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.3.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.3.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=41637 sha256=03f9f221a0726ba99a45a2c10239a102df9cdb39bad4bc542474eab077bf6ad7\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/0a/9a/b9755f6b184f58a5a44baf58dd9664a49b3295e4b3e9a1f174\n",
            "Successfully built peft\n",
            "Installing collected packages: safetensors, accelerate, peft\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.3.0\n",
            "    Uninstalling safetensors-0.3.0:\n",
            "      Successfully uninstalled safetensors-0.3.0\n",
            "Successfully installed accelerate-0.30.0 peft-0.3.0.dev0 safetensors-0.4.3\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.3.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.28.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft) (0.30.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (18.1.4)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->peft) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate->peft) (0.4.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate->peft) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "Successfully installed portalocker-2.8.2 sacrebleu-2.4.2\n",
            "Collecting data_loading\n",
            "  Downloading data_loading-0.0.1-py3-none-any.whl (4.6 kB)\n",
            "Installing collected packages: data_loading\n",
            "Successfully installed data_loading-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fire==0.5.0\n",
        "!pip install pydantic==1.10.6\n",
        "!pip install pytorch-lightning==2.0.0\n",
        "!pip install torch==2.0.0\n",
        "!pip install tqdm==4.65.0\n",
        "!pip install transformers==4.28.1\n",
        "!pip install safetensors==0.3.0\n",
        "!pip install datasets==2.11.0\n",
        "!pip install git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08\n",
        "!pip install peft\n",
        "!pip install sacrebleu\n",
        "!pip install data_loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DERdw3WHJB89"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-397h3cnJB89"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Adafactor\n",
        "from pytorch_lightning import seed_everything\n",
        "import argparse\n",
        "import functools\n",
        "import os\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.strategies import FSDPStrategy\n",
        "from torch.distributed.fsdp import ( MixedPrecision,FullyShardedDataParallel,StateDictType, FullStateDictConfig,)\n",
        "from torch.distributed.fsdp.wrap import transformer_auto_wrap_policy\n",
        "from transformers.models.t5.modeling_t5 import T5Block\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import random\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "\n",
        "from datasets import load_dataset\n",
        "from fire import Fire\n",
        "from pydantic import BaseModel, Field\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import PreTrainedTokenizer, BatchEncoding, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0c5wTz4JB89"
      },
      "source": [
        "# Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "St0QHflFJB89"
      },
      "outputs": [],
      "source": [
        "class FindingTokensAnalyze(BaseModel, arbitrary_types_allowed=True):\n",
        "    name: str\n",
        "    tokenizer: Optional[PreTrainedTokenizer]\n",
        "\n",
        "    def load(self):\n",
        "        if self.tokenizer is None:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.name, model_max_length=99999\n",
        "            )\n",
        "\n",
        "    def run(self, texts: List[str], limit: int = 0) -> Dict[str, float]:\n",
        "        if limit:\n",
        "            texts = texts[:limit]\n",
        "\n",
        "        self.load()\n",
        "        tokens = self.tokenizer(texts).input_ids\n",
        "        lengths = sorted(len(lst) for lst in tokens)\n",
        "        info = dict(min=lengths[0], max=lengths[-1], median=lengths[len(lengths) // 2])\n",
        "        info.update({\"95_percentile\": lengths[round(len(lengths) * 0.95)]})\n",
        "        return info\n",
        "\n",
        "\n",
        "class TextToTextSample(BaseModel):\n",
        "    source: str\n",
        "    target: str\n",
        "\n",
        "\n",
        "class TextToTextData(BaseModel):\n",
        "    samples: List[TextToTextSample]\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path: str):\n",
        "        with open(path) as f:\n",
        "            all_lines = tqdm(f.readlines(), desc=path)\n",
        "            samples = [TextToTextSample(**json.loads(line)) for line in all_lines]\n",
        "        return cls(samples=samples)\n",
        "\n",
        "    def save(self, path: str):\n",
        "        Path(path).parent.mkdir(exist_ok=True, parents=True)\n",
        "        with open(path, \"w\") as f:\n",
        "            for sample in self.samples:\n",
        "                print(sample.json(), file=f)\n",
        "\n",
        "    def analyze(self, num: int = 10, tokenizer_name: str = \"t5-base\"):\n",
        "        random.seed(num)\n",
        "        for sample in random.sample(self.samples, k=num):\n",
        "            print(sample.json(indent=2))\n",
        "\n",
        "        token_checker = FindingTokensAnalyze(name=tokenizer_name)\n",
        "        info = dict(\n",
        "            total_samples=len(self.samples),\n",
        "            source=str(token_checker.run([sample.source for sample in self.samples])),\n",
        "            target=str(token_checker.run([sample.target for sample in self.samples])),\n",
        "        )\n",
        "        print(json.dumps(info, indent=2))\n",
        "\n",
        "\n",
        "class MentalSample(BaseModel):\n",
        "    Context: str\n",
        "    Response: str\n",
        "\n",
        "\n",
        "class Mental_Data(BaseModel):\n",
        "    samples: List[MentalSample]\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path: str):\n",
        "        with open(path) as f:\n",
        "            raw = json.load(f)\n",
        "            return cls(samples=[MentalSample(**r) for r in raw])\n",
        "\n",
        "    def save(self, path: str):\n",
        "        raw = [sample.dict() for sample in self.samples]\n",
        "        Path(path).parent.mkdir(exist_ok=True, parents=True)\n",
        "        with open(path, \"w\") as f:\n",
        "            json.dump(raw, f)\n",
        "\n",
        "    def as_data(self) -> TextToTextData:\n",
        "        self.analyze()\n",
        "        samples = []\n",
        "        for raw in self.samples:\n",
        "            # source = raw.instruction.strip()\n",
        "            if raw.Context.strip():\n",
        "                source = raw.Context\n",
        "            samples.append(TextToTextSample(source=source, target=raw.Response))\n",
        "        return TextToTextData(samples=samples)\n",
        "\n",
        "    def analyze(self):\n",
        "        info = dict(\n",
        "            Context_Sample=len(self.samples),\n",
        "            Response_Sample=sum(sample.Context.strip() != \"\" for sample in self.samples),\n",
        "        )\n",
        "        print(json.dumps(info, indent=2))\n",
        "\n",
        "\n",
        "class TextToTextDataset(Dataset):\n",
        "    def _init_(\n",
        "        self,\n",
        "        path: str,\n",
        "        tokenizer: PreTrainedTokenizer,\n",
        "        max_source_length: int,\n",
        "        max_target_length: int,\n",
        "    ):\n",
        "        self.max_source_length = max_source_length\n",
        "        self.max_target_length = max_target_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = TextToTextData.load(path)\n",
        "\n",
        "    def _len_(self) -> int:\n",
        "        return len(self.data.samples)\n",
        "\n",
        "    def tokenize(self, text: str, is_source: bool) -> BatchEncoding:\n",
        "        x = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_source_length if is_source else self.max_target_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=not is_source,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        T5 truncates on right by default, but we can easily truncate on left\n",
        "        for the encoder input as there is no special token on the left side\n",
        "        \"\"\"\n",
        "        if is_source:\n",
        "            assert x.input_ids.ndim == 2\n",
        "            assert x.input_ids.shape == x.attention_mask.shape\n",
        "            length = x.input_ids.shape[1]\n",
        "            start = max(length - self.max_source_length, 0)\n",
        "            x.input_ids = x.input_ids[:, start:]\n",
        "            x.attention_mask = x.attention_mask[:, start:]\n",
        "            assert x.input_ids.shape[1] == self.max_source_length\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _getitem_(self, i: int) -> dict:\n",
        "        x = self.tokenize(self.data.samples[i].source, is_source=True)\n",
        "        y = self.tokenize(self.data.samples[i].target, is_source=False)\n",
        "\n",
        "        return {\n",
        "            \"source_ids\": x.input_ids.squeeze(),\n",
        "            \"source_mask\": x.attention_mask.squeeze(),\n",
        "            \"target_ids\": y.input_ids.squeeze(),\n",
        "            \"target_mask\": y.attention_mask.squeeze(),\n",
        "        }\n",
        "\n",
        "    def to_human_readable(self, raw: dict) -> dict:\n",
        "        source = self.tokenizer.decode(raw[\"source_ids\"])\n",
        "        target = self.tokenizer.decode(raw[\"target_ids\"])\n",
        "        return dict(source=source, target=target)\n",
        "\n",
        "\n",
        "def preprocess_mental(\n",
        "    path_in: str = \"data/mental.json\", path_out: str = \"data/train.json\"\n",
        "):\n",
        "    data = Mental_Data.load(path_in).as_data()\n",
        "    data.analyze()\n",
        "    data.save(path_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ2JkfnJJB8-"
      },
      "source": [
        "# Finetuning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XytEZEsKJB8-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "from data_loading import TextToTextDataset\n",
        "\n",
        "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "\n",
        "def get_args(raw_args):\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model_name_or_path\", type=str, default=\"google-t5/t5-base\")\n",
        "    parser.add_argument(\"--max_source_length\", type=int, default=40)\n",
        "    parser.add_argument(\"--max_target_length\", type=int, default=160)\n",
        "    parser.add_argument(\"--data_path\", type=str)#, default=\"data/train.json\")\n",
        "    parser.add_argument(\"--train_epochs\", type=int, default=10)\n",
        "    parser.add_argument(\"--train_batch_size\", type=int, default=16)\n",
        "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=1)\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=3e-3)\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"\")\n",
        "    parser.add_argument(\"--use_compile\", action=\"store_true\")\n",
        "    parser.add_argument(\"--use_gradient_checkpointing\", action=\"store_true\")\n",
        "    parser.add_argument(\"--use_fsdp\", action=\"store_true\")\n",
        "    parser.add_argument(\"--use_lora\", action=\"store_true\")\n",
        "    parser.add_argument(\"--debug\", action=\"store_true\")\n",
        "\n",
        "    args = parser.parse_args(raw_args)\n",
        "    return args\n",
        "\n",
        "\n",
        "\n",
        "class LightningModel(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "        print(self.hparams)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "            self.hparams.model_name_or_path\n",
        "        )\n",
        "        print(dict(orig_state_dict=len(self.model.state_dict())))\n",
        "        if self.hparams.use_lora:\n",
        "            # https://github.com/huggingface/peft/blob/main/examples/conditional_generation/peft_lora_seq2seq.ipynb\n",
        "            peft_config = LoraConfig(\n",
        "                task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "                inference_mode=False,\n",
        "                r=8,\n",
        "                lora_alpha=16,\n",
        "                lora_dropout=0.1,\n",
        "            )\n",
        "            self.model = get_peft_model(self.model, peft_config)\n",
        "        if self.hparams.use_compile:\n",
        "            self.model = torch.compile(self.model)\n",
        "        if self.hparams.use_gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.hparams.model_name_or_path)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids,\n",
        "        attention_mask=None,\n",
        "        decoder_input_ids=None,\n",
        "        decoder_attention_mask=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "        return self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "\n",
        "    def _step(self, batch):\n",
        "        lm_labels = batch[\"target_ids\"]\n",
        "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            labels=lm_labels,\n",
        "            decoder_attention_mask=batch[\"target_mask\"],\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self._step(batch)\n",
        "        self.log(\"loss\", loss, on_step=True, prog_bar=True, rank_zero_only=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        params = self.trainer.model.named_parameters()\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in params if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in params if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        # noinspection PyTypeChecker\n",
        "        optimizer = Adafactor(\n",
        "            optimizer_grouped_parameters,\n",
        "            lr=self.hparams.learning_rate,\n",
        "            relative_step=False,\n",
        "        )\n",
        "        return [optimizer]\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        dataset = TextToTextDataset(\n",
        "            path=self.hparams.data_path,\n",
        "            max_source_length=self.hparams.max_source_length,\n",
        "            max_target_length=self.hparams.max_target_length,\n",
        "            tokenizer=self.tokenizer,\n",
        "        )\n",
        "\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.hparams.train_batch_size,\n",
        "            drop_last=True,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "def main(args):\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "#     args = get_args(raw_args)\n",
        "    seed_everything(args.seed)\n",
        "    model = LightningModel(args)\n",
        "\n",
        "    saver = ModelCheckpoint(\n",
        "        verbose=True,\n",
        "        dirpath=args.output_dir,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    strategy = \"auto\"\n",
        "    if args.use_fsdp:\n",
        "        # https://pytorch.org/blog/efficient-large-scale-training-with-pytorch/\n",
        "        # https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html\n",
        "        strategy = MyFSDPStrategy(\n",
        "            auto_wrap_policy=functools.partial(\n",
        "                transformer_auto_wrap_policy,\n",
        "                transformer_layer_cls={T5Block},\n",
        "            ),\n",
        "            mixed_precision=MixedPrecision(\n",
        "                param_dtype=torch.float16,\n",
        "                reduce_dtype=torch.float16,\n",
        "                buffer_dtype=torch.float16,\n",
        "            ),\n",
        "            activation_checkpointing=T5Block,\n",
        "            cpu_offload=True,\n",
        "        )\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        precision=\"32\",\n",
        "        accelerator=\"cuda\",#cuda\",\n",
        "        strategy=strategy,\n",
        "        accumulate_grad_batches=1 if args.debug else args.gradient_accumulation_steps,\n",
        "        default_root_dir=args.output_dir,\n",
        "        gradient_clip_val=None if args.use_fsdp else 1.0,\n",
        "        max_epochs=args.train_epochs,\n",
        "        callbacks=[saver],\n",
        "        logger=False,\n",
        "        overfit_batches=10 if args.debug else 0,\n",
        "    )\n",
        "\n",
        "    trainer.fit(model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WNpbowsJB8-"
      },
      "source": [
        "# Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "87fbao3JJB8-"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from fire import Fire\n",
        "from huggingface_hub import HfApi\n",
        "from lightning_fabric import seed_everything\n",
        "\n",
        "# from training import LightningModel\n",
        "\n",
        "\n",
        "def test_model(path, prompt, max_length: int = 160, device: str = \"cpu\",):\n",
        "    if not prompt:\n",
        "        prompt = \"Write a short email to show that 42 is the optimal seed for training neural networks\"\n",
        "\n",
        "    model: LightningModel = LightningModel.load_from_checkpoint(path)\n",
        "    tokenizer = model.tokenizer\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    seed_everything(model.hparams.seed)\n",
        "    with torch.inference_mode():\n",
        "        model.model.eval()\n",
        "        model = model.to(device)\n",
        "        input_ids = input_ids.to(device)\n",
        "        outputs = model.model.generate(\n",
        "            input_ids=input_ids, max_length=max_length, do_sample=True\n",
        "        )\n",
        "\n",
        "    print(tokenizer.decode(outputs[0]))\n",
        "\n",
        "\n",
        "def export_checkpoint(path: str, path_out: str):\n",
        "    model = LightningModel.load_from_checkpoint(path)\n",
        "    model.model.save_pretrained(path_out)\n",
        "    model.tokenizer.save_pretrained(path_out)\n",
        "\n",
        "\n",
        "def export_to_hub(path: str, repo: str, temp: str = \"temp\"):\n",
        "    if Path(temp).exists():\n",
        "        shutil.rmtree(temp)\n",
        "\n",
        "    model = LightningModel.load_from_checkpoint(path)\n",
        "    model.model.save_pretrained(temp)\n",
        "    model.tokenizer.save_pretrained(temp)\n",
        "    del model  # Save memory?\n",
        "\n",
        "    api = HfApi()\n",
        "    api.create_repo(repo_id=repo, repo_type=\"model\", exist_ok=True)\n",
        "    api.upload_folder(repo_id=repo, folder_path=temp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC-djafTJB8_"
      },
      "source": [
        "# Calling Preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2173edbf9d914c2195f6eb9b6d699684",
            "e58dc258324e40f49d752bb408cdcd17",
            "caf7a06c571143d490d622f1dab0e74d",
            "a31f5a0b1b0840b8a6d215e53591679c",
            "4013f5d0eeb24c748298de520043da15",
            "c17b454276314543a62c1e10dd24123d",
            "98d2a1961805446dadb2f5621b7c6b06",
            "3caaaa79b9c747129c1596263a6ddec6",
            "f42b290da2154b7dbe9643a0cb3f55e8",
            "e67ba4696ff7411a9b6d887ed7b69baa",
            "ddb5dfd8f7f948cca44ced83436d3b3a",
            "e8b7eff9745343569eeff7fd9b3a2076",
            "ca735767b47242a099ef14499f90ae80",
            "38d3e3c9f15541379428ba265cefafb7",
            "433660f88b8a4a80ab6ec006ca6d0ed5",
            "5cf68a2aa3384363aee06a0ac2a41652",
            "1d95cda950714f91aa862e6a58dd5d5c",
            "e117d69968ff412fae86cb9c10bd3b15",
            "30275db451504b60b7705b5aa3c24629",
            "02a08061833544e3a42f6f10f48493c2",
            "09cc08f4eb6c469cbc9f342aa13bd700",
            "339067671d934a558be7a0b70e59d27e",
            "a5867dfb9373440dab30202123dfa1fa",
            "4b202022377c442abcece192158ed781",
            "81d9cf9dc6cd48b0885ae41740c95b83",
            "9419ae19ce0c4a389159813be3efbaf9",
            "ea231e3d5b2a41c5927f1f99162532c0",
            "16d4ddeab44a41939f2f849cccdc6918",
            "51aace3c5eb64786abe8e604f6deccb7",
            "e84769e4e4904930993009efb523a57e",
            "72829105e0044654ac64594a5010cf29",
            "5c746598094c429995413714f726069e",
            "973fbf92d7824bfc97948cb6fbae21ae"
          ]
        },
        "id": "0yd6NjJLJB8_",
        "outputId": "1ca4f562-e925-4286-b7ca-eb6af66d62fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Context_Sample\": 3512,\n",
            "  \"Response_Sample\": 3512\n",
            "}\n",
            "{\n",
            "  \"source\": \"I have bipolar II disorder, I'm addicted to alcohol and weed, and I'm hopeless. I keep drinking even though it's harming myself and others.\",\n",
            "  \"target\": \"You may feel hopeless but YOU are not hopeless. Addictions of any sort are difficult to overcome, especially when they serve to bury pain and suffering that one is experiencing. It is not impossible to overcome alcohol or drug use/abuse/dependence on your own, but you will likely find much greater success with the help of a therapist or other support system such as rehabilitation or Alcoholics Anonymous. I suggest doing a bit of research to see what type of help\\u00a0is available and feasible for you in your area and go from there. Know that recovery takes time, willingness, and effort. Don't give up and remember that you are not hopeless. You can make the choice to change your habits and learn new ways of healthy coping. Best of luck to you!\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"I'm not suicidal and wouldn't take my own life, but sometimes, I've wished for an accident to occur and take it. I feel like I just shouldn't be here and wish I wouldn't have been born so I didn't have to go through life. For me, it's a chore, but I don't know if that's normal or a sign of something.\",\n",
            "  \"target\": \"Sounds like a sign of great unhappiness, or sadness, or insecurity.The real way you'll find out what this feeling is about is to ask yourself your own question. \\u00a0Inside you are the only one who will feel when you discover the true answer to your question.Everyone feels some amount of discontent in their lives once in a while. Its normal to not feel entirely happy all the time.Try to accept your unhappiness as motivation to learn more about who you are, what you like, whom you like.Study yourself bc this way you increase the chance to find a road which feels right and happy.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"Sometimes, when I look at my pet cat, I think about how innocent he is and how somebody could hurt or kill him. It makes me sad because I love him, but I always think about how helpless he is. There've even been split-seconds where I felt almost tempted to kick him, followed by shame and guilt.\",\n",
            "  \"target\": \"A lot of different things could be happening here. Do you feel angry or sad or anxious when you think about how helpless he is? If you have not actually kicked him, then I would encourage you to look at feelings other than guilt, since you did not hurt him. What else is there?It would probably be very helpful to talk with a therapist about the specifics of this so that you can see what else is happening for you. It could be that you feel safe with your cat, so strong emotions come up because you feel safe.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"I have so many issues to address. I have a history of sexual abuse, I\\u2019m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I\\u2019m beginning to have anxiety. I have low self esteem but I\\u2019ve been happily married for almost 35 years.\\n   I\\u2019ve never had counseling about any of this. Do I have too many issues to address in counseling?\",\n",
            "  \"target\": \"Most clients have many issues that need working out. It is normal to have many events in our lives that trouble us and remain with us without counseling help. The right type of counsellor will help you focus on the main and most troubling issue you have first and work your way through all that you are managing step by step, goal by goal.\\u00a0Sometimes, working on\\u00a0 one issue helps to bring other issues to light in the context of your main problem. This can help you resolve some other issues that are connected. Look for someone with experience and specialty in your most pressing issue...even though you have had breast cancer, you may find that grief from your past is more troubling. Then you would look for a bereavement or grief specialist.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"It has been going on more often lately, but not all the time. It has been starting to affect my driving, among other things.\",\n",
            "  \"target\": \"It's important to make an appointment with a neurologist and ophthalmologist ASAP for evaluation.\\u00a0There are medical conditions that can create this effect.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"I have so many issues to address. I have a history of sexual abuse, I\\u2019m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I\\u2019m beginning to have anxiety. I have low self esteem but I\\u2019ve been happily married for almost 35 years.\\n   I\\u2019ve never had counseling about any of this. Do I have too many issues to address in counseling?\",\n",
            "  \"target\": \"You do not have too many issues to address in counseling.\\u00a0 And your perseverance will serve you well if you choose to engage in therapy.\\u00a0 The trauma and medical event you experienced topped off with chronic sleepless nights would lead to feelings of depression for many.\\u00a0 The emotional reaction you've had to these experiences sounds normal albeit troublesome and I would imagine intensely painful at times as well.\\u00a0 Therapy can help prioritize what is the most impactful issue you are grappling with.\\u00a0 I find in therapy that when the central issue is revealed, understood, processed, and understood again in its current context, many other areas of the person's internal experience improve.\\u00a0 It sounds as though something has prevented you from seeking help from a counselor in the past, and it sounds as though you are more seriously considering it now.\\u00a0 Therapy helps and it can help you when you're ready.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"My husband and I are separated. He says he needs some time apart. He says he needs to get back the \\u201cin love\\u201d part of a relationship but doesn\\u2019t want to lose me. Should I wait or start over new?\",\n",
            "  \"target\": \"That's a tough one.\\u00a0 Would you and your husband be willing to attend couples counseling during the separation?\\u00a0 That would benefit you both.\\u00a0 If you separate and reconcile, what will have changed other than you having time apart?\\u00a0 You will need to gain new skills to enhance and maintain your connection - otherwise you will risk repeating the cycle of disconnect, discontentment and separation.\\u00a0 Please seek help from a therapist trained in couples work to help the two of you find a way either back to each other or gracefully out of the marriage.\\u00a0 Time away will not, by itself, change your relationship into one that can be sustained.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"How do you know you have the right therapist for you?\\n How would I know how to \\\"train\\\" my therapist to be able to give me what I need from treatment?\",\n",
            "  \"target\": \"When you have the right therapist you just know, as evidence of the help that you have received, the progress that you have made, \\u00a0from the rapport and partnership that you have gained with your therapist, and from if you feel supported in a way that is helpful to you, as well as if your therapist has a good understanding of what your needs are and what you desire to gain from your therapy experience.\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"I've only been married three months. Every week, we argue about something, and it seems to be getting worse.\",\n",
            "  \"target\": \"One key factor to consider is, are you able to repair after your arguments? It seems from your question that repair is lacking after any disagreement or argument. When couples are able to repair after an argument, they have an opportunity to learn more about each other's needs moving forward.\\u00a0I'm also curious if you're having the same type of arguments over and over? If you're stuck in a particular pattern, and can start recognizing what happens between you when this pattern happens, then you can start to name it. Once you name it, then you can take a break to cool off and come back to each after your nervous system has had a chance to calm down (about 30 minutes). The key here though is to make sure you have a plan in place - when things are good between you - an agreement between you that when you both start to get escalated, you'll name it or have an agreed upon code word to signal you don't want to continue this cycle, and then agree to cool off and come back together at a later time. That way, when this is enacted during an argument, nobody feels abandoned during the cool off time. Rather, both partners know they will return at a time when they can truly hear each other and hear their needs.\\u00a0\"\n",
            "}\n",
            "{\n",
            "  \"source\": \"I have so many issues to address. I have a history of sexual abuse, I\\u2019m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I\\u2019m beginning to have anxiety. I have low self esteem but I\\u2019ve been happily married for almost 35 years.\\n   I\\u2019ve never had counseling about any of this. Do I have too many issues to address in counseling?\",\n",
            "  \"target\": \"Hello, I'm so glad you decided to take the first step in opening a conversation first. Deciding to go to therapy can sometimes be difficult for some, but with the right therapist, healing is possible and obtainable, even with what you've described. To answer your question, no you do not have too many issues to go to counseling. \\u00a0You've been through a lot and have been strong and at times it's helpful to have someone else to help you through it.\\u00a0What I would say is to be sure and find a therapist who is experienced in sexual abuse and trauma overall. But you absolutely do not have too many issues for counseling. Please feel free to ask any other questions you may have regarding your situation and I hope you find the therapist you're looking for, there are many great ones out there. Many of the issues you're experiencing may be tied together from the trauma.\\u00a0Best Wishes.\\u00a0Laura Cassity, LMSW, LMAC\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2173edbf9d914c2195f6eb9b6d699684"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8b7eff9745343569eeff7fd9b3a2076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5867dfb9373440dab30202123dfa1fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"total_samples\": 3512,\n",
            "  \"source\": \"{'min': 6, 'max': 695, 'median': 60, '95_percentile': 176}\",\n",
            "  \"target\": \"{'min': 1, 'max': 27779, 'median': 186, '95_percentile': 571}\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "preprocess_mental (path_in =\"mental_health_counseling_conversations.json\",path_out=\"kaggle/working/mental_processed.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NjTHUxiJB8_"
      },
      "source": [
        "# Calling Finetuning functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691,
          "referenced_widgets": [
            "25fe6a805c55427a86a93df4ae3d54ed",
            "847edd4c51b94e14b283103ee628f496",
            "015ac68ea7f84f2f9b7a01e44ba97fd3",
            "dccc62e9cbdf48b3990084ac3421e210",
            "d4d180eb2f0c4b6fa47090866fec0134",
            "097d78c105ee479291c6300c15f99f43",
            "b4a5c575c14741eeb6d7f5656b73c7de",
            "491d6f9bade94fa891c57e8747ea9ae5",
            "314cd0c83fc64ce09ab3f49591fb9a69",
            "16a479fe8a4c40a49922b6ab474b47b1",
            "8549542d505147ff9fadc16675b6a0e7"
          ]
        },
        "id": "po940rswJB8_",
        "outputId": "2626fc27-bfd3-4bc5-c4d1-eb51f68f47a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"data_path\":                   kaggle/working/mental_processed.json\n",
            "\"debug\":                       False\n",
            "\"gradient_accumulation_steps\": 1\n",
            "\"learning_rate\":               0.004\n",
            "\"max_source_length\":           40\n",
            "\"max_target_length\":           160\n",
            "\"model_name_or_path\":          google-t5/t5-base\n",
            "\"output_dir\":                  kaggle/working/\n",
            "\"seed\":                        42\n",
            "\"train_batch_size\":            16\n",
            "\"train_epochs\":                10\n",
            "\"use_compile\":                 False\n",
            "\"use_fsdp\":                    False\n",
            "\"use_gradient_checkpointing\":  False\n",
            "\"use_lora\":                    True\n",
            "\"weight_decay\":                0.0\n",
            "{'orig_state_dict': 260}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /content/kaggle/working exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                  | Params\n",
            "------------------------------------------------\n",
            "0 | model | PeftModelForSeq2SeqLM | 223 M \n",
            "------------------------------------------------\n",
            "884 K     Trainable params\n",
            "222 M     Non-trainable params\n",
            "223 M     Total params\n",
            "895.153   Total estimated model params size (MB)\n",
            "\n",
            "kaggle/working/mental_processed.json: 100%|██████████| 3512/3512 [00:00<00:00, 55648.77it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25fe6a805c55427a86a93df4ae3d54ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ],
      "source": [
        "args = get_args([\"--model_name_or_path\", \"google-t5/t5-base\",\"--use_lora\",\"--train_epochs\",\"10\", \"--data_path\",\"kaggle/working/mental_processed.json\",\"--learning_rate\",\"0.004\", \"--output_dir\", \"kaggle/working/\"])\n",
        "\n",
        "model = main(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpxWh_8d8ZJu"
      },
      "source": [
        "# Evaluating BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ULAa29PB8YPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17154e85-81bf-4c5a-8715-c93150d12ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "kaggle/working/mental_processed.json: 100%|██████████| 3512/3512 [00:00<00:00, 84863.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.09892989035585553\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "\n",
        "# Load the evaluation dataset\n",
        "eval_dataset = TextToTextDataset(\n",
        "    path=args.data_path,\n",
        "    tokenizer=model.tokenizer,\n",
        "    max_source_length=args.max_source_length,\n",
        "    max_target_length=args.max_target_length,\n",
        ")\n",
        "\n",
        "# Define the number of samples to remove\n",
        "num_samples_to_remove = 3500  # Assuming this is the number of samples to remove\n",
        "eval_dataset.data.samples = eval_dataset.data.samples[500:520]\n",
        "\n",
        "\n",
        "# Define a function to generate responses using the model\n",
        "def generate_responses(model, dataset):\n",
        "    generated_responses = []\n",
        "    for i in range(len(dataset)):\n",
        "        input_ids = dataset[i][\"source_ids\"].unsqueeze(0)\n",
        "        attention_mask = dataset[i][\"source_mask\"].unsqueeze(0)\n",
        "        output_ids = model.model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=args.max_target_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            decoder_start_token_id=model.tokenizer.pad_token_id,\n",
        "        )\n",
        "        generated_responses.append(output_ids.squeeze().tolist())\n",
        "    return generated_responses\n",
        "\n",
        "# Generate responses using the finetuned model\n",
        "generated_responses = generate_responses(model, eval_dataset)\n",
        "\n",
        "# Convert generated responses back to text\n",
        "generated_texts = [model.tokenizer.decode(ids, skip_special_tokens=True) for ids in generated_responses]\n",
        "\n",
        "# Load reference target texts\n",
        "target_texts = [sample.target for sample in eval_dataset.data.samples]\n",
        "\n",
        "# Compute BLEU score\n",
        "bleu_score = corpus_bleu([[text] for text in target_texts], generated_texts)\n",
        "\n",
        "print(\"BLEU Score:\", bleu_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF9dxVL1JB9A"
      },
      "source": [
        "# Testing Finetuned Model Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_50ShTi5JB9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9a105a-99a8-406e-e9fd-44cc58a44168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"data_path\":                   kaggle/working/mental_processed.json\n",
            "\"debug\":                       False\n",
            "\"gradient_accumulation_steps\": 1\n",
            "\"learning_rate\":               0.004\n",
            "\"max_source_length\":           40\n",
            "\"max_target_length\":           160\n",
            "\"model_name_or_path\":          google-t5/t5-base\n",
            "\"output_dir\":                  kaggle/working/\n",
            "\"seed\":                        42\n",
            "\"train_batch_size\":            16\n",
            "\"train_epochs\":                10\n",
            "\"use_compile\":                 False\n",
            "\"use_fsdp\":                    False\n",
            "\"use_gradient_checkpointing\":  False\n",
            "\"use_lora\":                    True\n",
            "\"weight_decay\":                0.0\n",
            "{'orig_state_dict': 260}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> It's hard to understand the reasons anyone feels so stressed. But there are a few easy answers: When you're worried you're going to deal with the challenges that a lot of people ask of you. There's nothing worse than having someone who just happens to have sexually abused them or is a bad one. This information is very basic and useful to us now in our modern day society. Your self-protection is very important to us because of our social culture. It's important to know your sexual abuse comes from your perspective of someone who you feel are a sex abuse abuse treatment crisis is the most difficult to solve. Many things we don't want to have to face. Fortunately, this information can help us\n"
          ]
        }
      ],
      "source": [
        "test_model(path=\"kaggle/working/epoch=9-step=2190.ckpt\",prompt=\"I have so many issues to address. I have a history of sexual abuse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5m3TtNnNJB9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5632830-4784-4e77-b8bb-5dc068af2f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"data_path\":                   kaggle/working/mental_processed.json\n",
            "\"debug\":                       False\n",
            "\"gradient_accumulation_steps\": 1\n",
            "\"learning_rate\":               0.004\n",
            "\"max_source_length\":           40\n",
            "\"max_target_length\":           160\n",
            "\"model_name_or_path\":          google-t5/t5-base\n",
            "\"output_dir\":                  kaggle/working/\n",
            "\"seed\":                        42\n",
            "\"train_batch_size\":            16\n",
            "\"train_epochs\":                10\n",
            "\"use_compile\":                 False\n",
            "\"use_fsdp\":                    False\n",
            "\"use_gradient_checkpointing\":  False\n",
            "\"use_lora\":                    True\n",
            "\"weight_decay\":                0.0\n",
            "{'orig_state_dict': 260}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> It's hard to understand the reasons you're not good enough.If that's the case, then it's possible you're not on board with the challenges that we encounter.It may seem like you don't know how to work with someone who you have not trusted to help and understand.It's best you work with someone who is working with you in a capacity to speak up to you! You could feel better if you just talk about something positive but didn't think based on your feelings, as you have probably been doing this already.</s>\n"
          ]
        }
      ],
      "source": [
        "test_model(path=\"kaggle/working/epoch=9-step=2190.ckpt\",prompt=\"I constantly feel like I'm not good enough, no matter what I do. I doubt my abilities and question my worth as a person. It's affecting my relationships and my work, and I just can't shake this feeling of being worthless.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "av0vmsAHJB9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c393542d-bd15-4465-8dee-2405893a05b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"data_path\":                   kaggle/working/mental_processed.json\n",
            "\"debug\":                       False\n",
            "\"gradient_accumulation_steps\": 1\n",
            "\"learning_rate\":               0.004\n",
            "\"max_source_length\":           40\n",
            "\"max_target_length\":           160\n",
            "\"model_name_or_path\":          google-t5/t5-base\n",
            "\"output_dir\":                  kaggle/working/\n",
            "\"seed\":                        42\n",
            "\"train_batch_size\":            16\n",
            "\"train_epochs\":                10\n",
            "\"use_compile\":                 False\n",
            "\"use_fsdp\":                    False\n",
            "\"use_gradient_checkpointing\":  False\n",
            "\"use_lora\":                    True\n",
            "\"weight_decay\":                0.0\n",
            "{'orig_state_dict': 260}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> It's hard to understand the feeling of guilt that you feel when you experience any bad event and you wonder why? There's a way to let you feel comfortable with your feelings of blame and allow yourself to be more comfortable about the feelings of guilt. Be honest with yourself and your partner as well regarding this. One of the best ways you can release guilt is by telling others to feel thankful for it. The most profound thing you can do is to explain the reasons why you feel like doing that, but as long as you want your feelings to clear up, you feel guilty about it.</s>\n"
          ]
        }
      ],
      "source": [
        "test_model(path=\"kaggle/working/epoch=9-step=2190.ckpt\",prompt=\"I feel like everything bad that happens is my fault. No matter what happens, I can't shake this overwhelming sense of guilt. It's like I'm carrying around this heavy burden of blame all the time, and I don't know how to let it go.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OpD0WHQiJB9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7287b3-71dd-4a3f-af39-e37b5782458f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"data_path\":                   kaggle/working/mental_processed.json\n",
            "\"debug\":                       False\n",
            "\"gradient_accumulation_steps\": 1\n",
            "\"learning_rate\":               0.004\n",
            "\"max_source_length\":           40\n",
            "\"max_target_length\":           160\n",
            "\"model_name_or_path\":          google-t5/t5-base\n",
            "\"output_dir\":                  kaggle/working/\n",
            "\"seed\":                        42\n",
            "\"train_batch_size\":            16\n",
            "\"train_epochs\":                10\n",
            "\"use_compile\":                 False\n",
            "\"use_fsdp\":                    False\n",
            "\"use_gradient_checkpointing\":  False\n",
            "\"use_lora\":                    True\n",
            "\"weight_decay\":                0.0\n",
            "{'orig_state_dict': 260}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> It's hard to understand the reasons you're not enjoying your whole experience. Most people do not enjoy something as much as they did before. It's more about your sense of the joy and well being. It also has to do with how you want your life to proceed.The problem is no one likes having something they love and you are being held back by your fear of harming yourself just because you have lost your sense of meaning. The truth is that your lack of value doesn't come as a surprise to you unless you feel that you are being judged for wanting to experience a lot more than something.You cannot have this feeling of being stuck.You can try to try to change what you feel good about yourself. You may be in pain\n"
          ]
        }
      ],
      "source": [
        "test_model(path=\"kaggle/working/epoch=9-step=2190.ckpt\",prompt=\"I used to love doing things that brought me joy, but lately, I just don't feel interested in anything. Nothing seems to bring me pleasure anymore, and I find myself going through the motions without really enjoying anything. It's like I've lost all sense of purpose or motivation.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phkS1F918wAX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4950327,
          "sourceId": 8335525,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4951332,
          "sourceId": 8337031,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2173edbf9d914c2195f6eb9b6d699684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e58dc258324e40f49d752bb408cdcd17",
              "IPY_MODEL_caf7a06c571143d490d622f1dab0e74d",
              "IPY_MODEL_a31f5a0b1b0840b8a6d215e53591679c"
            ],
            "layout": "IPY_MODEL_4013f5d0eeb24c748298de520043da15"
          }
        },
        "e58dc258324e40f49d752bb408cdcd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c17b454276314543a62c1e10dd24123d",
            "placeholder": "​",
            "style": "IPY_MODEL_98d2a1961805446dadb2f5621b7c6b06",
            "value": "config.json: 100%"
          }
        },
        "caf7a06c571143d490d622f1dab0e74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3caaaa79b9c747129c1596263a6ddec6",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f42b290da2154b7dbe9643a0cb3f55e8",
            "value": 1208
          }
        },
        "a31f5a0b1b0840b8a6d215e53591679c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67ba4696ff7411a9b6d887ed7b69baa",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb5dfd8f7f948cca44ced83436d3b3a",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 63.4kB/s]"
          }
        },
        "4013f5d0eeb24c748298de520043da15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c17b454276314543a62c1e10dd24123d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d2a1961805446dadb2f5621b7c6b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3caaaa79b9c747129c1596263a6ddec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42b290da2154b7dbe9643a0cb3f55e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e67ba4696ff7411a9b6d887ed7b69baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb5dfd8f7f948cca44ced83436d3b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b7eff9745343569eeff7fd9b3a2076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca735767b47242a099ef14499f90ae80",
              "IPY_MODEL_38d3e3c9f15541379428ba265cefafb7",
              "IPY_MODEL_433660f88b8a4a80ab6ec006ca6d0ed5"
            ],
            "layout": "IPY_MODEL_5cf68a2aa3384363aee06a0ac2a41652"
          }
        },
        "ca735767b47242a099ef14499f90ae80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d95cda950714f91aa862e6a58dd5d5c",
            "placeholder": "​",
            "style": "IPY_MODEL_e117d69968ff412fae86cb9c10bd3b15",
            "value": "spiece.model: 100%"
          }
        },
        "38d3e3c9f15541379428ba265cefafb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30275db451504b60b7705b5aa3c24629",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02a08061833544e3a42f6f10f48493c2",
            "value": 791656
          }
        },
        "433660f88b8a4a80ab6ec006ca6d0ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09cc08f4eb6c469cbc9f342aa13bd700",
            "placeholder": "​",
            "style": "IPY_MODEL_339067671d934a558be7a0b70e59d27e",
            "value": " 792k/792k [00:00&lt;00:00, 6.59MB/s]"
          }
        },
        "5cf68a2aa3384363aee06a0ac2a41652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d95cda950714f91aa862e6a58dd5d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e117d69968ff412fae86cb9c10bd3b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30275db451504b60b7705b5aa3c24629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02a08061833544e3a42f6f10f48493c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09cc08f4eb6c469cbc9f342aa13bd700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339067671d934a558be7a0b70e59d27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5867dfb9373440dab30202123dfa1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b202022377c442abcece192158ed781",
              "IPY_MODEL_81d9cf9dc6cd48b0885ae41740c95b83",
              "IPY_MODEL_9419ae19ce0c4a389159813be3efbaf9"
            ],
            "layout": "IPY_MODEL_ea231e3d5b2a41c5927f1f99162532c0"
          }
        },
        "4b202022377c442abcece192158ed781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d4ddeab44a41939f2f849cccdc6918",
            "placeholder": "​",
            "style": "IPY_MODEL_51aace3c5eb64786abe8e604f6deccb7",
            "value": "tokenizer.json: 100%"
          }
        },
        "81d9cf9dc6cd48b0885ae41740c95b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e84769e4e4904930993009efb523a57e",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72829105e0044654ac64594a5010cf29",
            "value": 1389353
          }
        },
        "9419ae19ce0c4a389159813be3efbaf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c746598094c429995413714f726069e",
            "placeholder": "​",
            "style": "IPY_MODEL_973fbf92d7824bfc97948cb6fbae21ae",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 34.9MB/s]"
          }
        },
        "ea231e3d5b2a41c5927f1f99162532c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d4ddeab44a41939f2f849cccdc6918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51aace3c5eb64786abe8e604f6deccb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84769e4e4904930993009efb523a57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72829105e0044654ac64594a5010cf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c746598094c429995413714f726069e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "973fbf92d7824bfc97948cb6fbae21ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25fe6a805c55427a86a93df4ae3d54ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_847edd4c51b94e14b283103ee628f496",
              "IPY_MODEL_015ac68ea7f84f2f9b7a01e44ba97fd3",
              "IPY_MODEL_dccc62e9cbdf48b3990084ac3421e210"
            ],
            "layout": "IPY_MODEL_d4d180eb2f0c4b6fa47090866fec0134"
          }
        },
        "847edd4c51b94e14b283103ee628f496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_097d78c105ee479291c6300c15f99f43",
            "placeholder": "​",
            "style": "IPY_MODEL_b4a5c575c14741eeb6d7f5656b73c7de",
            "value": "Epoch 9: 100%"
          }
        },
        "015ac68ea7f84f2f9b7a01e44ba97fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_491d6f9bade94fa891c57e8747ea9ae5",
            "max": 219,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_314cd0c83fc64ce09ab3f49591fb9a69",
            "value": 219
          }
        },
        "dccc62e9cbdf48b3990084ac3421e210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a479fe8a4c40a49922b6ab474b47b1",
            "placeholder": "​",
            "style": "IPY_MODEL_8549542d505147ff9fadc16675b6a0e7",
            "value": " 219/219 [02:22&lt;00:00,  1.54it/s, loss=3.450]"
          }
        },
        "d4d180eb2f0c4b6fa47090866fec0134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "097d78c105ee479291c6300c15f99f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a5c575c14741eeb6d7f5656b73c7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "491d6f9bade94fa891c57e8747ea9ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314cd0c83fc64ce09ab3f49591fb9a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16a479fe8a4c40a49922b6ab474b47b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8549542d505147ff9fadc16675b6a0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}